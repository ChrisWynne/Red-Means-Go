{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray, gray2rgb, rgb2hsv\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facial detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facial_detection_haar(filename):\n",
    "    img = io.imread(filename)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=3,\n",
    "        minSize=(30, 30),\n",
    "        flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 10)\n",
    "    return img, len(faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facial_recognition(filename, cnn=True):\n",
    "    image = face_recognition.load_image_file(filename)\n",
    "    if cnn:\n",
    "        face_locations = face_recognition.face_locations(image, model='cnn')\n",
    "    else:\n",
    "        face_locations = face_recognition.face_locations(image)\n",
    "    return image, len(face_locations), face_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facial_analysis(face_locations,image,config='age, gender, race, emotion'):\n",
    "    if len(face_locations)>0:\n",
    "        config = config.split(',')\n",
    "        config = [c.strip() for c in config]\n",
    "        results = []\n",
    "        im = Image.fromarray(image)\n",
    "        for f in face_locations:\n",
    "            face = im.crop((f[3],f[0],f[1],f[2]))\n",
    "            face = np.asarray(face)\n",
    "            demography = DeepFace.analyze(face,config)\n",
    "            results.append(demography)\n",
    "        return results\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facial_percentage(face_locations,image):\n",
    "    result = []\n",
    "    img_pixelcount = image_obj.shape[0]*image_obj.shape[1]\n",
    "    for f in face_locations:\n",
    "        face_pixels = (f[2]-f[0])*(f[1]-f[3])\n",
    "        result.append(face_pixels/img_pixelcount)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_database(IMG_DIR):\n",
    "    cols = ['videoId','numFaces','emotions','face_locations','face_percent']\n",
    "    feature_df = pd.DataFrame(columns=cols)\n",
    "    for filename in os.listdir(IMG_DIR):\n",
    "        genders = []\n",
    "        image_obj,num_faces,face_coords = facial_recognition(IMG_DIR+'/'+filename)\n",
    "        #face locations coordinates are (top, right, bottom, left)\n",
    "        analysis = facial_analysis(face_coords,image_obj)\n",
    "        if len(analysis)>0:\n",
    "            emotions = [analysis[f]['dominant_emotion'] for f in analysis]\n",
    "            age = [analysis[f]['age'] for f in analysis]\n",
    "            gender = [analysis[f]['gender'] for f in analysis]\n",
    "            race = [analysis[f]['dominant_race'] for f in analysis]\n",
    "        else:\n",
    "            emotions=age=gender=race=np.nan\n",
    "            \n",
    "        face_percent = facial_percentage(face_coords,image_obj)\n",
    "        feature_df = feature_df.append({'videoId':filename[:-4],'numFaces':num_faces,'emotions':emotions,'age':age,\n",
    "                                        'gender':gender,'race':race,'face_locations':face_coords,\n",
    "                                        'face_percent':face_percent}, ignore_index=True)\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlib.DLIB_USE_CUDA = True\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_database_batches(IMG_DIR):\n",
    "    df = pd.DataFrame(columns = ['videoId','numFaces','face_locations','age','gender','emotions','race'])\n",
    "    batch = 0\n",
    "    videoId_batch = []\n",
    "    face_locations_batch = []\n",
    "    faces_batch = []\n",
    "    img_obj_batch = []\n",
    "    last_file = os.listdir(IMG_DIR)[-1]\n",
    "    num_batch = 0\n",
    "    for filename in os.listdir(IMG_DIR):\n",
    "        image = face_recognition.load_image_file(IMG_DIR+'/'+filename)\n",
    "        img_obj_batch.append(image)\n",
    "        videoId_batch.append(filename[:-4])\n",
    "        batch += 1\n",
    "        if batch == 250 or filename == last_file:\n",
    "            print('Batch {0} Start!'.format(num_batch))\n",
    "            face_locations_batch = face_recognition.batch_face_locations(img_obj_batch,number_of_times_to_upsample=1, batch_size=batch)\n",
    "            empty_indices = [empty_ix for empty_ix, element in enumerate(face_locations_batch) if element == []]\n",
    "\n",
    "            for index in sorted(empty_indices, reverse=True):\n",
    "                del face_locations_batch[index]\n",
    "                del videoId_batch[index]\n",
    "                del img_obj_batch[index]\n",
    "            for ix in range(len(face_locations_batch)):\n",
    "                im = Image.fromarray(img_obj_batch[ix])\n",
    "                for f in face_locations_batch[ix]:\n",
    "                    face = im.crop((f[3],f[0],f[1],f[2]))\n",
    "                    face = np.asarray(face)\n",
    "                    faces_batch.append(face)\n",
    "                \n",
    "            analysis_counter = 0\n",
    "            analysis = DeepFace.analyze(faces_batch)\n",
    "        \n",
    "            for i in range(len(face_locations_batch)):\n",
    "                f = face_locations_batch[i]\n",
    "                emotions = [] \n",
    "                age = []\n",
    "                gender = []\n",
    "                race = []\n",
    "                for j in range(len(f)):\n",
    "                    analysis_counter += 1\n",
    "                    curr_analysis = analysis['instance_'+str(analysis_counter)]\n",
    "                    emotions.append(curr_analysis['dominant_emotion'])\n",
    "                    age.append(curr_analysis['age'])\n",
    "                    gender.append(curr_analysis['gender'])\n",
    "                    race.append(curr_analysis['dominant_race'])\n",
    "                df = df.append({'videoId':videoId_batch[i],'numFaces':len(f),'emotions':emotions,'age':age,\n",
    "                                'gender':gender,'race':race,'face_locations':f}, ignore_index=True)\n",
    "            batch = 0\n",
    "            videoId_batch = []\n",
    "            face_locations_batch = []\n",
    "            faces_batch = []\n",
    "            img_obj_batch = []\n",
    "            print('Batch {0} Done!'.format(num_batch))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
