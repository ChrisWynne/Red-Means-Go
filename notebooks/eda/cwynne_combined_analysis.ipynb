{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "sys.path.insert(0, os.path.abspath(\"../../\" + 'src/scraping'))\n",
    "import metadata as meta\n",
    "sys.path.insert(0, os.path.abspath(\"../../\" + \"src/modeling\"))\n",
    "import basic_stats as basic\n",
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_thumbnails(save_dir, chan_ids, master_df):\n",
    "    for chan_id in chan_ids:\n",
    "        chan_df = master_df[master_df['channelId'] == chan_id]\n",
    "        chan_vids = meta.download_df_thumbs(chan_df,save_dir,'medium')\n",
    "    chan_basic_df = basic.basic_image_stats(save_dir)\n",
    "    full_chan = master_df.merge(chan_basic_df,on='videoId')\n",
    "    full_chan = full_chan.drop_duplicates(subset='videoId')\n",
    "    return full_chan\n",
    "\n",
    "def get_corr(img_feats, meta_feats,df,sign):\n",
    "    corrs = []\n",
    "    for col in meta_feats:\n",
    "        for col2 in img_feats:\n",
    "        #     col = 'z_views'\n",
    "        #     col2 = 'contrast'\n",
    "            step1 = df[df[col].notnull()]\n",
    "            filtered = step1[step1[col2].notnull()]\n",
    "            corr = np.corrcoef(filtered[col],filtered[col2])[0][1]\n",
    "            corrs.append([col2, col, corr])\n",
    "#             if sign == \"-\":\n",
    "#                 if corr < 0:\n",
    "#                     print(col, col2, corr)\n",
    "#                     print('---------------')\n",
    "#             else:\n",
    "#                 if corr > 0:\n",
    "#                     print(col, col2, corr)\n",
    "#                     print('---------------')\n",
    "    corr_df = pd.DataFrame(corrs, columns=['img_ft','meta_ft','corr'])\n",
    "    return corr_df\n",
    "\n",
    "\n",
    "# plots single emoition vs z views for all specified emotions\n",
    "def get_emotions_df(emotions,in_df,meta_col):\n",
    "    emotions_data = []\n",
    "    for targ in emotions:\n",
    "        emotion = in_df['emotions'].apply(lambda x: targ in x if type(x) == str else x)\n",
    "        emotions_data.append(in_df[emotion == True][meta_col].describe())\n",
    "    #     plt.scatter(emotion,face_data['z_views'])\n",
    "    #     plt.title(targ + \" vs. z_views\")\n",
    "    #     plt.xlabel(targ)\n",
    "    #     plt.ylabel('z_views')\n",
    "    #     plt.show()\n",
    "    emotions_df = pd.DataFrame(emotions_data).reset_index()\n",
    "    emotions_df['emotion'] = emotions\n",
    "    return emotions_df\n",
    "                    \n",
    "def get_range(col_name, df):\n",
    "    stats = df[col_name].describe()\n",
    "    col_range = np.arange(stats['25%'],stats['max'],stats['std']/3)\n",
    "    return col_range\n",
    "\n",
    "def tune_params(df, c1, c2, meta_col):\n",
    "    baseline_stats = df[meta_col].describe()\n",
    "    base_mean = baseline_stats['mean']\n",
    "    base_median = baseline_stats['50%']\n",
    "#     print(\"baseline:     \",\n",
    "#           \"count:\",baseline_stats['count'],\n",
    "#           \"mean:\",baseline_stats['mean'].round(3),\n",
    "#           \"median:\",baseline_stats['50%'].round(3))\n",
    "    rel_stats = []\n",
    "    c1_range = get_range(c1,df)\n",
    "    c2_range = get_range(c2,df)\n",
    "    for c1_cutoff in c1_range:\n",
    "        for c2_cutoff in c2_range:\n",
    "            filtered = df.apply(lambda x: x[c1] > c1_cutoff and x[c2] > c2_cutoff,axis=1)\n",
    "            stats = df[filtered][meta_col].describe()\n",
    "            cur_count = stats['count']\n",
    "            cur_mean = stats['mean']\n",
    "            cur_median = stats['50%']\n",
    "            cur_stats_list = [c1,c1_cutoff,c2,c2_cutoff,cur_count, cur_mean, cur_median]\n",
    "            rel_stats.append(cur_stats_list)\n",
    "    res_df = pd.DataFrame(rel_stats, columns=['col1','col1cutoff','col2','col2cutoff','count','mean','median'])\n",
    "    relevant_df = res_df[res_df['count'] > 0] # gets rid of param combinations with no results\n",
    "    # filters out param combinations that did worse than the baseline\n",
    "    better_df = relevant_df[relevant_df.apply(\n",
    "        lambda x: x['mean'] > base_mean and x['median'] > base_median,axis=1)]\n",
    "    return better_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config variables\n",
    "emotions = ['angry', 'happy', 'sad', 'fear', 'neutral', 'surprise']\n",
    "describe_cols = ['mean','std','25%','50%','75%']\n",
    "numerical_img_feats = ['unique_rgb_ratio','mean_hue',\n",
    "                       'mean_saturation','mean_brightness', 'contrast',\n",
    "                       'edge_score','numFaces']\n",
    "meta_feats = ['viewCount','z_views']\n",
    "master_df = pd.read_csv(\"../../data/local/fortnite/video_data/fortnite_master_metadata_updated_facial_features.csv\")\n",
    "save_dir = \"../../data/local/fortnite/thumbnails/\"\n",
    "chan_ids = all_meta['channelId'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloads thumbnails not in local storage and computes basic image statistics, takes a decent bit\n",
    "final_df = get_all_thumbnails(save_dir, chan_ids, master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different subsets of data\n",
    "final_df = final_df[final_df['z_views'].notnull()]\n",
    "face_data = final_df[final_df['numFaces'].notnull()]\n",
    "no_face_data = final_df[final_df['numFaces'].isnull()]\n",
    "all_face = final_df.fillna(value={\"numFaces\":0})\n",
    "# dataset to use for eda\n",
    "analysis_df = all_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotion stats for each descriptive stat for each meta column\n",
    "plt.rcParams['figure.figsize'] = [6, 4]\n",
    "emotions_df = get_emotions_df(emotions,analysis_df,meta_feats[0])\n",
    "plt.bar(emotions_df['emotion'],emotions_df['count'],color=['red','green','blue','purple','grey','orange'])\n",
    "plt.xlabel('emotion')\n",
    "plt.ylabel('count')\n",
    "plt.title(\"Video count per emotion\")\n",
    "plt.show()\n",
    "for meta_feat in meta_feats:\n",
    "    emotions_df = get_emotions_df(emotions,analysis_df,meta_feat)\n",
    "    for col in describe_cols:\n",
    "        plt.bar(emotions_df['emotion'],emotions_df[col],color=['red','green','blue','purple','grey','orange'])\n",
    "        plt.xlabel('emotion')\n",
    "        plt.ylabel(col)\n",
    "        plt.title(meta_feat + \" (\" + col + \") per emotion\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table of corr coeffecients for convenience\n",
    "all_corrs = get_corr(numerical_img_feats, meta_feats, analysis_df, '-')\n",
    "all_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot summary of each numerical image feature vs each meta column with correlation in title\n",
    "for col in numerical_img_feats:\n",
    "    for meta_col in meta_feats:\n",
    "        plt.scatter(analysis_df[col],analysis_df[meta_col])\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(meta_col)\n",
    "        cur_corr_df = all_corrs[all_corrs.apply(lambda x: x['img_ft'] == col and x['meta_ft'] == meta_col,axis=1)]\n",
    "        cur_corr = cur_corr_df.iloc[0]['corr']\n",
    "        plt.title(col + \" vs. \" + meta_col + \" Corr: \" + str(cur_corr.round(3)))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame()\n",
    "for meta_feat in meta_feats:\n",
    "    cur_corr_df = all_corrs[all_corrs['meta_ft'] == meta_feat]\n",
    "    c1, c2 = cur_corr_df.sort_values(by='corr',ascending=False)['img_ft'].iloc[0:2].values\n",
    "    # this takes a while bc of the many combinations, may re-write the way I get the ranges\n",
    "    tuned_df = tune_params(analysis_df,c1,c2,meta_feat) \n",
    "    tuned_df['mm_sum'] = tuned_df['mean'] + tuned_df['median']\n",
    "    #old cell break\n",
    "    top_df = tuned_df.sort_values(by='mm_sum',ascending=False)\n",
    "    rgb_cutoff = top_df['col1cutoff'].describe()['mean']\n",
    "    sat_cutoff = top_df['col2cutoff'].describe()['mean']\n",
    "    top_cut = analysis_df[analysis_df.apply(\n",
    "        lambda x: x[c1] > rgb_cutoff and x[c2] > sat_cutoff,axis=1)]\n",
    "\n",
    "    baseline_stats = analysis_df[meta_feat].describe().round(4)\n",
    "    baseline_stats['type'] = 'baseline'\n",
    "    baseline_stats['meta_col'] = baseline_stats.name\n",
    "\n",
    "    top_cut_stats = top_cut[meta_feat].describe().round(4)\n",
    "    top_cut_stats['type'] = 'top_cut'\n",
    "    top_cut_stats['meta_col'] = top_cut_stats.name\n",
    "\n",
    "    cur_summary_df = pd.DataFrame([baseline_stats,top_cut_stats]).reset_index(drop=True)\n",
    "    summary_df = pd.concat([summary_df,cur_summary_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis using threshold cutoff for 2 features with the highest + correlation to the meta_col\n",
    "# results are stats of the \"top cut\" that meet said criteria\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not adjusted for multiple meta feats\n",
    "targ_col = 'z_views'\n",
    "X_train, X_test, y_train, y_test = train_test_split(analysis_df[numerical_img_feats],\n",
    "                                                    analysis_df[targ_col],\n",
    "                                                    train_size=.9)\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_preds = rf.predict(X_test)\n",
    "print(\"RF Score:\",rf.score(X_test,y_test))\n",
    "plt.scatter(rf_preds,y_test)\n",
    "plt.title('RF ' + targ_col + ' Predictions vs Actual')\n",
    "plt.xlabel('prediction')\n",
    "plt.ylabel('actual')\n",
    "plt.show()\n",
    "# feat_importances = pd.Series(dict(zip(numerical_img_feats,rf.feature_importances_)))\n",
    "# print(\"RF Feat Importances:\\n\",feat_importances.sort_values(ascending=False))\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_preds = gbr.predict(X_test)\n",
    "print(\"GBR Score:\",gbr.score(X_test,y_test))\n",
    "plt.scatter(gbr_preds,y_test)\n",
    "plt.title('GBR ' + targ_col + ' Predictions vs Actual')\n",
    "plt.xlabel('prediction')\n",
    "plt.ylabel('actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_lvl_df = pd.DataFrame()\n",
    "for num_feat in numerical_img_feats:\n",
    "    for num_feat2 in numerical_img_feats:\n",
    "        for num_feat3 in numerical_img_feats:\n",
    "            for num_feat4 in numerical_img_feats:\n",
    "                col_name = num_feat + \"/\" + num_feat2 + \"/\" + num_feat3 + \"/\" + num_feat4 \n",
    "                high_lvl_df[col_name] = analysis_df[num_feat]*analysis_df[num_feat2]*analysis_df[num_feat3]*analysis_df[num_feat4]\n",
    "high_lvl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_train, high_test, targ_train, targ_test = train_test_split(high_lvl_df, analysis_df['viewCount'])\n",
    "lr = LinearRegression()\n",
    "lr.fit(high_train, targ_train)\n",
    "lr.score(high_test, targ_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_preds = lr.predict(high_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(lr_preds, targ_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df['has_face'] = analysis_df['numFaces'] > 0\n",
    "poor_perf = analysis_df[analysis_df['z_views'] < -1]\n",
    "good_perf = analysis_df[analysis_df['z_views'] > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poor_data = []\n",
    "good_data = []\n",
    "for num_feat in numerical_img_feats:\n",
    "    poor_data.append(poor_perf[num_feat].describe())\n",
    "    good_data.append(good_perf[num_feat].describe())\n",
    "poor_stats = pd.DataFrame(poor_data).drop(\"count\",axis=1).T\n",
    "good_stats = pd.DataFrame(good_data).drop('count',axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 5]\n",
    "x = np.arange(len(good_stats.index))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "for num_feat in numerical_img_feats:\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(x - width/2,good_stats[num_feat],width,label='Good Performance')\n",
    "    rects2 = ax.bar(x + width/2,poor_stats[num_feat],width,label='Poor Performance')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(good_stats.index)\n",
    "    ax.set_title(num_feat)\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_meta = pd.read_csv(\"../../data/local/fortnite/video_data/fortnite_master_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big_df = pd.read_csv('../../data/local/fortnite/video_data/merged_df.csv').drop(\"Unnamed: 0\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_faces = final_df[final_df['numFaces'].isnull()]['videoId']\n",
    "# faces = final_df[final_df['numFaces'].notnull()]['videoId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in np.random.choice(len(faces),size=20):\n",
    "#     display(Image.open(\"../../data/local/fortnite/thumbnails/\" + faces.iloc[i] + \".jpg\"))\n",
    "#     print(final_df.iloc[i]['numFaces'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in np.random.choice(len(no_faces),size=20):\n",
    "#     display(Image.open(\"../../data/local/fortnite/thumbnails/\" + no_faces.iloc[i] + \".jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotion = sorted_df['emotions'].apply(lambda x: len(ast.literal_eval(x)) if type(x) == str else 0)\n",
    "# # print(\"Emotion:\",targ)\n",
    "# display(emotion.describe())\n",
    "# plt.scatter(emotion,sorted_df['z_views'])\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# numerical_img_feats = ['unique_rgb_ratio','num_rgb','mean_hue',\n",
    "#                        'mean_saturation','mean_brightness', 'contrast',\n",
    "#                        'edge_score','numFaces']\n",
    "# meta_feats = ['z_views']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_corr(numerical_img_feats, meta_feats, face_data, '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_corr(numerical_img_feats, meta_feats, face_data, '+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c1 = 'num_rgb'\n",
    "# c2 = 'edge_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuned_df = tune_params(face_data,c1,c2)\n",
    "# tuned_df['mm_sum'] = tuned_df['mean'] + tuned_df['median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_df = tuned_df.sort_values(by='mm_sum',ascending=False)\n",
    "# rgb_cutoff = top_df['col1cutoff'].describe()['mean']\n",
    "# sat_cutoff = top_df['col2cutoff'].describe()['mean']\n",
    "# # face_data['z_views'].describe()\n",
    "# top_cut = face_data[face_data.apply(\n",
    "#     lambda x: x[c1] > rgb_cutoff and x[c2] > sat_cutoff,axis=1)]\n",
    "# top_cut['z_views'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_200 = pd.read_csv('../../data/local/fortnite/video_data/merged_df.csv').drop(\"Unnamed: 0\",axis=1)\n",
    "# full_views = top_200[top_200['z_views'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = RandomForestRegressor()\n",
    "# rf.fit(full_views[basic_img_feats],full_views[['position']])\n",
    "# rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_stats = sorted_df['z_views'].describe()\n",
    "# print(\"baseline:     \",\n",
    "#       \"count:\",baseline_stats['count'],\n",
    "#       \"mean:\",baseline_stats['mean'].round(3),\n",
    "#       \"median:\",baseline_stats['50%'].round(3))\n",
    "# # print('---------------------------------------')\n",
    "# #['baseline',0,baseline_stats['count'],baseline_stats['mean'],baseline_stats['50%']]\n",
    "# rel_stats = []\n",
    "# c1 = 'num_rgb'\n",
    "# c1_range = get_range(c1,sorted_df)\n",
    "# c2 = 'mean_saturation'\n",
    "# c2_range = get_range(c2, sorted_df)\n",
    "# for c1_cutoff in c1_range:\n",
    "#     for c2_cutoff in c2_range:\n",
    "#         filtered = sorted_df.apply(lambda x: x[c1] > c1_cutoff and x[c2] > c2_cutoff,axis=1)\n",
    "#         stats = sorted_df[filtered]['z_views'].describe()\n",
    "#         cur_count = stats['count']\n",
    "#         cur_mean = stats['mean']\n",
    "#         cur_median = stats['50%']\n",
    "#         cur_stats_list = [c1,c1_cutoff,c2,c2_cutoff,cur_count, cur_mean, cur_median]\n",
    "#         rel_stats.append(cur_stats_list)\n",
    "# res_df = pd.DataFrame(rel_stats, columns=['col1','col1cutoff','col2','col2cutoff','count','mean','median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not_null_df = res_df[res_df['mean'].notnull()]\n",
    "# not_null_df[not_null_df.apply(lambda x: x['mean'] > .5 and x['median']> .2,axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c1 = 'mean_saturation'\n",
    "# c1_stats = sorted_df[c1].describe()\n",
    "# c1_range = np.arange(c1_stats['25%'],c1_stats['75%'],c1_stats['std']/3)\n",
    "# c1_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col = 'contrast'\n",
    "# print(sorted_df[col].describe())\n",
    "# plt.scatter(sorted_df['contrast'],sorted_df['z_views'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for vid_id in basic_stats_df['videoId'].values:\n",
    "#     if vid_id not in df['videoId'].values:\n",
    "#         print(vid_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df = df.merge(basic_stats_df,how=\"left\",on=\"videoId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime.now().strftime(\"_%m_%d_%y\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
